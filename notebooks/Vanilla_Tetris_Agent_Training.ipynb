{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# list directories where packages are stored\n",
    "# note that the parent directory of te repo is added automatically\n",
    "GYM_FOLDER = \"gym-t99\"\n",
    "\n",
    "# get this notebook's current working directory\n",
    "nb_cwd = os.getcwd()\n",
    "# get name of its parent directory\n",
    "nb_parent = os.path.dirname(nb_cwd)\n",
    "# add packages to path\n",
    "sys.path.insert(len(sys.path), nb_parent)\n",
    "sys.path.insert(len(sys.path), os.path.join(nb_parent, GYM_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.6.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "registered = gym.envs.registration.registry.env_specs.copy()\n",
    "\n",
    "import gym_t99\n",
    "import t_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove basic-v0 from registry\n",
      "Remove t99-v0 from registry\n",
      "Remove t99sc-v0 from registry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'gym_t99' from '/Users/surajvathsa/Projects/DL-stuff/RL/239AS_T99_RL_Agent/gym-t99/gym_t99/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "\n",
    "# this code removes environment from gym's registry\n",
    "env_dict = gym.envs.registration.registry.env_specs.copy()\n",
    "for env in env_dict:\n",
    "    if env not in registered:\n",
    "        print(\"Remove {} from registry\".format(env))\n",
    "        del gym.envs.registration.registry.env_specs[env]\n",
    "\n",
    "imp.reload(gym_t99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib as plt\n",
    "# configure matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# configure torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple random agent to play aginst and test\n",
    "class RandomEnemySC:    \n",
    "    # this interface needs to be supported for any agent\n",
    "    def action(self, observation):\n",
    "        return np.random.choice(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_gym = gym.make('gym_t99:t99sc-v0', num_players = 1, enemy=RandomEnemySC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  2  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]]\n"
     ]
    }
   ],
   "source": [
    "frame = custom_gym.render(mode=\"debug\")\n",
    "# frame[0][-4, 2:6] = 1\n",
    "print(frame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = {\n",
    "    \"reward\": 0,\n",
    "    \"state\": deepcopy(custom_gym.state)\n",
    "}\n",
    "\n",
    "observations, reward, done, _ = custom_gym.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  2  2  2  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  2  0  0  0  0  0 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]]\n"
     ]
    }
   ],
   "source": [
    "print(observations[0][2].players[0].board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holes(board):\n",
    "    num_holes = 0\n",
    "    for col in range(3, board.shape[1]-3):\n",
    "        row = 0\n",
    "        while row < board.shape[0] - 3 and board[row][col] == 0:\n",
    "            row += 1\n",
    "        while row < board.shape[0] - 3:\n",
    "            if board[row][col] == 0:\n",
    "                num_holes += 1\n",
    "            row += 1\n",
    "    return num_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bumpiness_and_height(board):\n",
    "    mask = board != 0\n",
    "    invert_heights = np.where(mask.any(axis=0), np.argmax(mask, axis=0), board.shape[0])\n",
    "    heights = board.shape[0] - invert_heights\n",
    "    total_height = np.sum(heights)\n",
    "    currs = heights[:-1]\n",
    "    nexts = heights[1:]\n",
    "    diffs = np.abs(currs - nexts)\n",
    "    total_bumpiness = np.sum(diffs)\n",
    "    return total_bumpiness, total_height\n",
    "\n",
    "def bumpiness(board):\n",
    "    '''Sum of the differences of heights between pair of columns'''\n",
    "    total_bumpiness = 0\n",
    "    max_bumpiness = 0\n",
    "    min_ys = []\n",
    "\n",
    "    for col in zip(*board[:board.shape[0]-3, 3:board.shape[1]-3]):\n",
    "        i = 0\n",
    "        while i < board.shape[0] and col[i] == 0:\n",
    "            i += 1\n",
    "        min_ys.append(i)\n",
    "\n",
    "    for i in range(len(min_ys) - 1):\n",
    "        bumpiness = abs(min_ys[i] - min_ys[i+1])\n",
    "        max_bumpiness = max(bumpiness, max_bumpiness)\n",
    "        total_bumpiness += abs(min_ys[i] - min_ys[i+1])\n",
    "\n",
    "    return total_bumpiness, max_bumpiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num lines cleared -> obs[0][-1]\n",
    "def calculate_features(player):\n",
    "    \n",
    "    board = player.board\n",
    "    num_lines_cleared = player.num_lines_cleared\n",
    "    num_holes = get_holes(board)\n",
    "    total_bumpiness, total_height = get_bumpiness_and_height(board)\n",
    "\n",
    "    \n",
    "    return np.array([num_holes, total_bumpiness, total_height, num_lines_cleared])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_state_features(next_states):\n",
    "    next_state_features = []\n",
    "    for state in next_states:\n",
    "        features = calculate_features(state.players[0])\n",
    "        next_state_features.append(features)\n",
    "    return next_state_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Viet Nguyen <nhviet1009@gmail.com>\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Linear(4, 64), nn.ReLU(inplace=True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(64, 64), nn.ReLU(inplace=True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(64, 1))\n",
    "\n",
    "        self._create_weights()\n",
    "\n",
    "    def _create_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "# Transition is same as experience.\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \"\"\"A cyclic buffer i.e. newer experiences over-write \n",
    "    the older experiences when the capacity of ReplayMemory\n",
    "    is reached.\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "    \n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1)%self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "GAMMA = 0.95\n",
    "EPS_START = 1\n",
    "EPS_END = 0\n",
    "EPS_STOP_EPISODE = 500\n",
    "TARGET_UPDATE = 1 # How often we update the target network \n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 5\n",
    "\n",
    "policy_net = DQN(n_actions).to(device)\n",
    "target_net = DQN(n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "memory = ReplayMemory(30000)\n",
    "\n",
    "steps_done = 0\n",
    "eps_threshold = (EPS_START - EPS_END) / EPS_STOP_EPISODE\n",
    "eps = EPS_START\n",
    "\n",
    "\n",
    "def select_action(next_states):\n",
    "    \"\"\"Follows Epsilon-Greedy selection strategy\n",
    "    \"\"\"\n",
    "    global steps_done\n",
    "    global eps_threshold\n",
    "    global eps\n",
    "    \n",
    "    sample = random.random()\n",
    "    \n",
    "    \n",
    "    steps_done += 1\n",
    "    \n",
    "    next_states = [torch.from_numpy(next_state) for next_state in next_states]\n",
    "    index = None\n",
    "    if sample > eps: # Greedy\n",
    "        with torch.no_grad():\n",
    "            index = randint(0, len(next_states) - 1)\n",
    "    else:\n",
    "        next_states = torch.stack(next_states).type(torch.FloatTensor)\n",
    "        predictions = policy_net(next_states)[:, 0]\n",
    "        index = torch.argmax(predictions).item()\n",
    "    \n",
    "    if eps > EPS_END:\n",
    "        eps -= eps_threshold\n",
    "    \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from itertools import count\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE) # Sample a batch from memory\n",
    "    \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    \n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "\n",
    "    \n",
    "    next_states = policy_net(state_batch)\n",
    "\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    \n",
    "    \n",
    "    state_action_values = policy_net(state_batch)\n",
    "    \n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Compute the expected Q values using bellman equation\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute MSE Loss\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "[[10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  4  4  4  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  4  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  3  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  3  3  3  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  6  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  6  6  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  6  1  1  1  1 10 10 10]\n",
      " [10 10 10  0  0  0  1  1  1  1  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  2  0  0  2  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  0  0  0  2  2  2  0  0 10 10 10]\n",
      " [10 10 10  0  2  0  0  0  4  0  0  0  0 10 10 10]\n",
      " [10 10 10  1  1  1  1  4  4  4  0  0  0 10 10 10]\n",
      " [10 10 10  5  5  0  0  2  0  0  0  2  2 10 10 10]\n",
      " [10 10 10  0  5  5  0  2  2  2  0  2  0 10 10 10]\n",
      " [10 10 10  0  7  7  0  0  6  6  0  2  0 10 10 10]\n",
      " [10 10 10  0  7  7  0  6  6  0  7  7  0 10 10 10]\n",
      " [10 10 10  0  0  6  6  2  0  0  7  7  0 10 10 10]\n",
      " [10 10 10  0  6  6  0  2  2  2  0  3  0 10 10 10]\n",
      " [10 10 10  0  0  6  0  0  5  0  0  3  0 10 10 10]\n",
      " [10 10 10  0  0  6  6  5  5  0  0  3  3 10 10 10]\n",
      " [10 10 10  0  5  0  6  5  0  7  7  2  0 10 10 10]\n",
      " [10 10 10  5  5  0  3  3  3  7  7  2  0 10 10 10]\n",
      " [10 10 10  5  0  0  3  0  0  0  2  2  0 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]]\n",
      "17\n",
      "17\n",
      "[[10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  3  3  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  3  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  3  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  0  0  0  0  4  0 10 10 10]\n",
      " [10 10 10  0  0  4  0  0  0  0  4  4  0 10 10 10]\n",
      " [10 10 10  0  4  4  0  0  0  0  0  4  0 10 10 10]\n",
      " [10 10 10  0  0  4  0  0  1  0  0  1  0 10 10 10]\n",
      " [10 10 10  0  0  5  0  2  1  0  0  1  0 10 10 10]\n",
      " [10 10 10  0  5  5  0  2  1  0  0  1  0 10 10 10]\n",
      " [10 10 10  0  5  0  2  2  1  2  0  1  0 10 10 10]\n",
      " [10 10 10  3  3  3  0  7  7  2  2  2  0 10 10 10]\n",
      " [10 10 10  3  0  0  0  7  7  6  6  0  0 10 10 10]\n",
      " [10 10 10  4  0  0  0  0  6  6  0  1  0 10 10 10]\n",
      " [10 10 10  4  4  0  0  0  2  2  0  1  0 10 10 10]\n",
      " [10 10 10  4  6  0  0  0  2  0  0  1  0 10 10 10]\n",
      " [10 10 10  0  6  6  0  0  2  0  0  1  3 10 10 10]\n",
      " [10 10 10  0  0  6  0  0  7  7  3  3  3 10 10 10]\n",
      " [10 10 10  0  6  6  0  4  7  7  0  6  6 10 10 10]\n",
      " [10 10 10  6  6  0  0  4  4  0  6  6  0 10 10 10]\n",
      " [10 10 10  4  4  4  0  4  0  1  1  1  1 10 10 10]\n",
      " [10 10 10  0  4  3  3  3  0  0  0  0  5 10 10 10]\n",
      " [10 10 10  0  0  3  0  6  0  0  3  5  5 10 10 10]\n",
      " [10 10 10  0  3  3  3  6  6  0  3  5  0 10 10 10]\n",
      " [10 10 10  0  3  0  0  0  6  0  3  3  0 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]]\n",
      "17\n",
      "[[10 10 10  0  0  0  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  6  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  6  6  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  6  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  5  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  5  5  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  5  6  6  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  6  6  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  6  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  6  6  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  7  7  2  6  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  7  7  2  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  2  2  0  0  0  0  0  0  0 10 10 10]\n",
      " [10 10 10  0  0  1  0  0  0  0  3  3  3 10 10 10]\n",
      " [10 10 10  0  0  1  0  0  0  0  3  0  0 10 10 10]\n",
      " [10 10 10  0  0  1  7  7  0  0  6  6  0 10 10 10]\n",
      " [10 10 10  0  0  1  7  7  0  6  6  0  0 10 10 10]\n",
      " [10 10 10  0  0  5  5  0  0  0  4  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  5  5  4  4  4  0  0 10 10 10]\n",
      " [10 10 10  0  0  0  0  4  4  4  4  4  0 10 10 10]\n",
      " [10 10 10  0  0  0  6  6  0  0  0  4  4 10 10 10]\n",
      " [10 10 10  0  0  6  6  0  0  0  0  4  1 10 10 10]\n",
      " [10 10 10  0  0  0  5  0  0  0  0  0  1 10 10 10]\n",
      " [10 10 10  0  0  5  5  0  0  3  0  0  1 10 10 10]\n",
      " [10 10 10  0  0  5  0  3  3  3  0  0  1 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-eb34a65151ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mnext_state_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_next_state_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnext_state_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-e71dc07ed11e>\u001b[0m in \u001b[0;36mcalculate_next_state_features\u001b[0;34m(next_states)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnext_state_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnext_state_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext_state_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-7d3e3a9ce3c2>\u001b[0m in \u001b[0;36mcalculate_features\u001b[0;34m(player)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_lines_cleared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_lines_cleared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnum_holes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_holes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_bumpiness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bumpiness_and_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-e2a71e821935>\u001b[0m in \u001b[0;36mget_holes\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_lasted = []\n",
    "num_episodes = 3000\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    custom_gym.reset()\n",
    "    action = {\n",
    "        \"reward\": 0,\n",
    "        \"state\": deepcopy(custom_gym.state)\n",
    "    }\n",
    "\n",
    "    observations, reward, done, _ = custom_gym.step(action)\n",
    "\n",
    "    current_state = custom_gym.state\n",
    "    next_states, next_state_rewards = observations\n",
    "    for t in count():\n",
    "\n",
    "        next_state_features = calculate_next_state_features(next_states)\n",
    "        \n",
    "        next_state_index = select_action(next_state_features)\n",
    "        \n",
    "        \n",
    "        action = {\n",
    "            \"reward\" : next_state_rewards[next_state_index],\n",
    "            \"state\" : next_states[next_state_index]\n",
    "        }\n",
    "        \n",
    "\n",
    "        new_next_states, reward, done, _ = custom_gym.step(action)\n",
    "        \n",
    "        if reward != 1:\n",
    "            print(reward)\n",
    "        \n",
    "        reward = torch.tensor([reward], device=device).type(torch.FloatTensor)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Observe new state\n",
    "#         if not done:\n",
    "#             next_state = torch.from_numpy(calculate_features(obs)).type(torch.FloatTensor)\n",
    "#             save_next_state = torch.unsqueeze(next_state, 0)\n",
    "#         else:\n",
    "#             next_state = None\n",
    "#             save_next_state = None\n",
    "\n",
    "        if not done:\n",
    "            save_next_state = torch.unsqueeze(torch.tensor(calculate_features(next_states[next_state_index].players[0])).type(torch.FloatTensor), 0) \n",
    "        else:\n",
    "            save_next_state = None\n",
    "            \n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(\n",
    "            torch.unsqueeze(torch.tensor(calculate_features(current_state.players[0])).type(torch.FloatTensor), 0), \n",
    "            action, \n",
    "            save_next_state, \n",
    "            reward\n",
    "        )\n",
    "\n",
    "        # Move to the next state\n",
    "        current_state = next_states[next_state_index]\n",
    "        next_states, next_state_rewards = new_next_states\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        \n",
    "\n",
    "        if done:\n",
    "            time_lasted.append(t)\n",
    "            if i_episode % 100 == 0 and i_episode != 0:\n",
    "                frame = custom_gym.render(mode=\"debug\")\n",
    "                print(frame[0])\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "custom_gym.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "xs = [i for i in range(1, 3001)]\n",
    "plt.plot(xs, time_lasted)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"time lasted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157, 76, 43, 36, 65, 45, 42, 55, 50, 36, 51, 38, 38, 34, 28, 34, 37, 30, 29, 34, 21, 30, 28, 30, 27, 31, 28, 21, 24, 39, 28, 25, 27, 25, 23, 25, 22, 19, 32, 26, 22, 27, 22, 26, 17, 23, 20, 25, 23, 19, 19, 21, 17, 21, 18, 25, 21, 19, 19, 14, 18, 16, 20, 17, 21, 20, 23, 22, 27, 14, 23, 12, 11, 13, 20, 16, 21, 17, 22, 19, 23, 18, 16, 19, 23, 15, 25, 20, 16, 15, 21, 14, 19, 20, 19, 22, 18, 19, 23, 20, 19, 19, 14, 20, 24, 13, 18, 16, 11, 18, 24, 16, 18, 15, 22, 15, 19, 26, 16, 22, 23, 19, 25, 19, 21, 21, 20, 20, 22, 19, 18, 19, 24, 27, 17, 18, 21, 28, 19, 24, 18, 10, 21, 20, 19, 17, 19, 8, 14, 17, 16, 22, 13, 21, 13, 17, 22, 18, 24, 25, 20, 19, 17, 17, 18, 18, 18, 18, 24, 21, 18, 22, 21, 25, 24, 24, 21, 14, 14, 18, 18, 23, 16, 18, 13, 14, 20, 19, 20, 18, 11, 22, 27, 22, 19, 25, 20, 23, 22, 15, 16, 20, 18, 20, 21, 18, 20, 16, 16, 14, 22, 21, 16, 17, 18, 18, 22, 16, 19, 21, 18, 12, 24, 21, 17, 16, 23, 17, 15, 21, 22, 24, 23, 18, 19, 20, 17, 13, 16, 13, 16, 21, 19, 16, 19, 21, 17, 16, 16, 19, 22, 13, 21, 25, 24, 16, 20, 20, 14, 23, 13, 20, 18, 20, 21, 18, 20, 24, 16, 17, 15, 23, 20, 20, 14, 17, 20, 19, 17, 16, 19, 15, 16, 14, 22, 19, 17, 20, 20, 21, 21, 20, 18, 22, 21, 19, 15, 25, 19, 12, 22, 14, 21, 22, 22, 12, 19, 18, 24, 19, 23, 23, 22, 20, 17, 20, 19, 27, 17, 18, 18, 19, 23, 17, 15, 13, 18, 20, 23, 19, 19, 21, 15, 21, 16, 17, 16, 23, 20, 25, 19, 16, 25, 21, 23, 19, 22, 13, 25, 21, 19, 21, 12, 12, 23, 18, 16, 14, 18, 22, 20, 15, 27, 15, 20, 14, 17, 19, 17, 19, 26, 21, 22, 21, 19, 23, 26, 18, 17, 25, 24, 17, 23, 18, 16, 22, 16, 27, 20, 24, 18, 20, 26, 23, 19, 18, 22, 18, 20, 18, 19, 23, 20, 19, 19, 18, 22, 20, 17, 19, 15, 16, 18, 13, 25, 25, 19, 18, 24, 23, 15, 25, 21, 20, 25, 17, 15, 17, 17, 17, 19, 18, 24, 16, 20, 19, 18, 20, 22, 24, 22, 21, 23, 18, 18, 15, 17, 21, 20, 15, 20, 16, 23, 13, 17, 25, 22, 17, 23, 21, 23, 18, 21, 22, 18, 16, 18, 19, 20, 14, 21, 20, 16, 21, 18, 21, 25, 13, 14, 14, 16, 20, 17, 22, 20, 23, 16, 13, 20, 17, 21, 14, 19, 24, 24, 16, 19, 23, 23, 18, 25, 22, 22, 19, 21, 21, 17, 23, 16, 18, 24, 15, 18, 24, 19, 21, 20, 22, 20, 18, 24, 17, 19, 15, 24, 20, 24, 19, 22, 15, 16, 20, 17, 18, 25, 16, 24, 15, 17, 14, 18, 23, 15, 22, 18, 23, 18, 23, 18, 13, 23, 22, 21, 15, 22, 13, 21, 20, 24, 18, 18, 25, 23, 22, 22, 19, 17, 19, 23, 12, 22, 19, 20, 23, 11, 20, 14, 17, 14, 24, 17, 19, 23, 22, 18, 20, 17, 21, 13, 23, 18, 17, 27, 18, 23, 20, 18, 21, 16, 25, 22, 24, 18, 21, 18, 21, 18, 19, 17, 17, 13, 19, 12, 24, 19, 16, 16, 19, 23, 24, 19, 21, 21, 16, 18, 24, 24, 14, 23, 22, 19, 19, 17, 20, 19, 16, 21, 18, 23, 18, 18, 24, 23, 17, 23, 21, 15, 14, 20, 18, 18, 11, 21, 12, 19, 20, 17, 16, 19, 15, 18, 17, 21, 23, 22, 25, 20, 20, 16, 24, 21, 25, 19, 12, 15, 16, 17, 23, 21, 16, 13, 18, 19, 17, 21, 19, 24, 19, 24, 16, 14, 17, 17, 15, 17, 24, 17, 14, 24, 23, 13, 18, 19, 21, 19, 16, 18, 17, 22, 17, 24, 23, 18, 21, 14, 20, 28, 17, 22, 22, 20, 30, 25, 18, 18, 23, 14, 23, 25, 23, 13, 14, 18, 14, 19, 17, 20, 22, 18, 21, 15, 19, 16, 22, 20, 12, 21, 19, 19, 21, 19, 17, 19, 27, 21, 25, 19, 21, 18, 18, 15, 17, 12, 27, 16, 29, 21, 19, 17, 25, 20, 15, 14, 16, 19, 19, 19, 17, 21, 20, 12, 22, 22]\n"
     ]
    }
   ],
   "source": [
    "print(time_lasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
